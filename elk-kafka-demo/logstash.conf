# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.
# input {
#   beats {
#     port => 5044
#   }
# }

input {
    beats {
      port => 5044
      type => beat
    }
    udp{
      port => 9988
      type => udplog
    }
    tcp {  
    ##host:port就是上面appender中的 destination，这里其实把logstash作为服务，开启9601端口接收logback发出的消息  
        host => "localhost"  
        port => 9601  
    #模式选择为server  
        mode => "server"  
        tags => ["tags"]  
    ##格式json  
       codec => json_lines         
    }  

} 
filter {
  if [type] == "udplog" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp}\s+%{LOGLEVEL:severity}\s+\[%{DATA:service},%{DATA:trace},%{DATA:span},%{DATA:exportable}\]\s+%{DATA:pid}\s+---\s+\[%{DATA:thread}\]\s+%{DATA:class}\s+:\s+%{GREEDYDATA:rest}" }
      add_field => [ "received_at", "%{@timestamp}" ]
      add_field => [ "received_from", "%{host}" ]
    }
    # date {
    #   match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    # }
  }
}
output {
  elasticsearch {
    hosts => ["localhost:9200"]
    #user => "elastic"
    #password => "changeme"
  }
  stdout { 
        codec => rubydebug
        #codec => json
  }
}
